---
layout: post
comments: true
title: Monte-Carlo Dropout
subtitle: "Incorporando  Meta-Conhecimento em Modelos de Deep Learning."
date: 2017-07-06
tags: [Post]
author: "Matheus Facure"
header-img: /img/fundo_main.png
modal-id: 12
thumbnail: /img/portfolio/mc-dropout/thumbnail.png
description: Recentemente, decidi dar um passo atrás e encarar os meus modelos sob uma perspectiva mais crítica. Como saber se meu modelo está aprendendo algo estatisticamente razoável? Quão confiável é o meu modelo? Mais importante ainda, como saber se meu modelo não vai quebrar diante de algo muito diferente de tudo que ele já viu? E como proceder diante dessas situações inusitadas? Este post fala principalmente sobre incerteza e sobre como injetá-la em modelos de redes neurais. Trata-se de um tópico ainda bastante obscuro, mesmo para a comunidade de aprendizado de máquina, mas que acredito que deveria ser encarado com mais atenção.
---

Este pots foi transferido para o blog do LAMFO. [Confira lá um pouco sobre Incerteza em Modelos de Deep Learning!](https://lamfo-unb.github.io/2017/10/22/Monte-Carlo-Dropout/)

O LAMFO (Laboratório de Aprendizado de Máquina para Finanças e Organizações) é um time de pesquisadores sensacionais, vinculado à Universidade de Brasília e liderado pelo professor Pedro Albuquerque.
